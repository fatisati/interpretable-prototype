{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae24cad-8044-46be-8c40-62ee51b7d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/icb/fatemehs.hashemig/codes/interpretable-ssl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9844f595-b610-4f7a-866f-ed378d35d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
      "INFO:pytorch_lightning.utilities.seed:Global seed set to 0\n",
      "/home/icb/fatemehs.hashemig/miniconda3/envs/apex-env/lib/python3.12/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/home/icb/fatemehs.hashemig/miniconda3/envs/apex-env/lib/python3.12/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n",
      "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
      " captum (see https://github.com/pytorch/captum).\n",
      "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n",
      "WARNING:root:multigrate is not installed. To use multigrate models, please install it first using \"pip install multigrate\".\n"
     ]
    }
   ],
   "source": [
    "from interpretable_ssl.trainers.swav import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c80fc1-4e3e-441b-9606-474cd4d50320",
   "metadata": {},
   "source": [
    "# reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05a159a-ea28-46e4-a72c-55573689a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import interpretable_ssl.trainers.base\n",
    "import interpretable_ssl.trainers.swav\n",
    "importlib.reload(interpretable_ssl.trainers.base)\n",
    "importlib.reload(interpretable_ssl.trainers.swav)\n",
    "from interpretable_ssl.trainers.swav import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572aa773-49cc-42c6-bf2c-3378a911090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset is None, loading hlca\n"
     ]
    }
   ],
   "source": [
    "t = SwAV(\n",
    "    dimensionality_reduction='pca',\n",
    "    k_neighbors=7,\n",
    "    training_type='semi_supervised',\n",
    "    fine_tuning_epochs=15,\n",
    "    pretraining_epochs=15,\n",
    "    augmentation_type='knn',\n",
    "    cvae_loss_scaler=0.0,\n",
    "    prot_decoding_loss_scaler=0,\n",
    "    workers=0, debug=True,\n",
    "    num_prototypes=300,\n",
    "    epsilon=0.02,\n",
    "    model_version=1,\n",
    "    dataset_id='hlca'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcbb107-6272-475f-966b-6fb88a6c769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.split_train_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ee06c4-1e25-457c-b701-d0134af2ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.ref = t.partial_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d67318f-925e-44e5-a5bd-bdbf92214b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10/15/24 10:44:56 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 10/15/24 10:44:56 - 0:00:00 - all_latent: None\n",
      "                                     augmentation_type: knn\n",
      "                                     base_lr: 4.8\n",
      "                                     batch_size: 512\n",
      "                                     cell_type_key: cell_type\n",
      "                                     checkpoint_freq: 25\n",
      "                                     condition_key: study\n",
      "                                     crops_for_assign: [0, 1]\n",
      "                                     cvae_loss_scaler: 0.0\n",
      "                                     cvae_reg: 0\n",
      "                                     dataset: hlca\n",
      "                                     dataset_id: hlca\n",
      "                                     debug: True\n",
      "                                     default_values: {'dataset_id': 'pbmc-immune', 'model_name_version': 3, 'num_prototypes': 128, 'hidden_dim': 64, 'latent_dims': 8, 'batch_size': 512, 'fine_tuning_epochs': 0, 'experiment_name': '', 'condition_key': 'study', 'cell_type_key': 'cell_type', 'linear_eval': False, 'only_eval': False, 'use_early_stopping': False, 'pretraining_epochs': 300, 'training_type': 'pretrain', 'pretrain_dataset_id': 'hlca', 'finetune_dataset_id': 'pbmc-immune', 'dump_name_version': 4, 'nmb_crops': [7], 'augmentation_type': 'knn', 'size_crops': [224], 'min_scale_crops': [0.14], 'max_scale_crops': [1], 'crops_for_assign': [0, 1], 'temperature': 0.1, 'epsilon': 0.05, 'sinkhorn_iterations': 3, 'feat_dim': 8, 'queue_length': 0, 'epoch_queue_starts': 15, 'base_lr': 4.8, 'final_lr': 0, 'freeze_prototypes_niters': 313, 'wd': 1e-06, 'warmup_epochs': 10, 'start_warmup': 0, 'cvae_reg': 0, 'dist_url': 'env://', 'world_size': -1, 'rank': 0, 'local_rank': 0, 'workers': 10, 'checkpoint_freq': 25, 'use_fp16': False, 'sync_bn': 'pytorch', 'syncbn_process_group_size': 8, 'seed': 31, 'model': '', 'optimizer': '', 'lr_schedule': '', 'queue': None, 'train_loader': '', 'training_stats': '', 'device': 'cuda', 'freezable_prototypes': False, 'cvae_loss_scaler': 0.0001, 'prot_decoding_loss_scaler': 5, 'hidden_mlp': 1024, 'swav_dim': 64, 'use_projector': False, 'model_version': 2, 'train_decoder': False, 'longest_path': 3, 'dimensionality_reduction': None, 'k_neighbors': 10, 'model_type': 'swav', 'job_name': ''}\n",
      "                                     device: cuda\n",
      "                                     dimensionality_reduction: pca\n",
      "                                     dist_url: env://\n",
      "                                     dump_checkpoints: /home/icb/fatemehs.hashemig/models//hlca/swav-only_iloss0_closs0.0_num-prot-300_latent8-semi_aug-knn7_ep0.02_model-v1_dimensionality_reduction-pca_k_neighbors-7/checkpoints\n",
      "                                     dump_name_version: 4\n",
      "                                     dump_path: /home/icb/fatemehs.hashemig/models//hlca/swav-only_iloss0_closs0.0_num-prot-300_latent8-semi_aug-knn7_ep0.02_model-v1_dimensionality_reduction-pca_k_neighbors-7\n",
      "                                     epoch_queue_starts: 15\n",
      "                                     epsilon: 0.02\n",
      "                                     experiment_name: swav-only_iloss0_closs0.0\n",
      "                                     feat_dim: 8\n",
      "                                     final_lr: 0\n",
      "                                     fine_tuning_epochs: 15\n",
      "                                     finetune_dataset_id: pbmc-immune\n",
      "                                     finetune_ds: hlca\n",
      "                                     finetuning: False\n",
      "                                     freezable_prototypes: False\n",
      "                                     freeze_prototypes_niters: 313\n",
      "                                     hidden_dim: 64\n",
      "                                     hidden_mlp: 1024\n",
      "                                     input_dim: 2000\n",
      "                                     job_name: \n",
      "                                     k_neighbors: 7\n",
      "                                     latent_dims: 8\n",
      "                                     linear_eval: False\n",
      "                                     local_rank: 0\n",
      "                                     longest_path: 3\n",
      "                                     lr_schedule: \n",
      "                                     max_scale_crops: [1]\n",
      "                                     min_scale_crops: [0.14]\n",
      "                                     model: \n",
      "                                     model_name_version: 3\n",
      "                                     model_type: swav\n",
      "                                     model_version: 1\n",
      "                                     nmb_crops: [7]\n",
      "                                     nmb_prototypes: 300\n",
      "                                     num_prototypes: 300\n",
      "                                     only_eval: False\n",
      "                                     optimizer: \n",
      "                                     original_ref: hlca\n",
      "                                     partial_ref: hlca\n",
      "                                     pretrain_dataset_id: hlca\n",
      "                                     pretraining_epochs: 15\n",
      "                                     prot_decoding_loss_scaler: 0\n",
      "                                     query: hlca\n",
      "                                     query_latent: None\n",
      "                                     queue: None\n",
      "                                     queue_length: 0\n",
      "                                     rank: 0\n",
      "                                     ref: hlca\n",
      "                                     ref_latent: None\n",
      "                                     seed: 31\n",
      "                                     sinkhorn_iterations: 3\n",
      "                                     size_crops: [224]\n",
      "                                     start_warmup: 0\n",
      "                                     swav_dim: 64\n",
      "                                     sync_bn: pytorch\n",
      "                                     syncbn_process_group_size: 8\n",
      "                                     temperature: 0.1\n",
      "                                     train_augmentation: knn\n",
      "                                     train_decoder: False\n",
      "                                     train_loader: \n",
      "                                     training_stats: \n",
      "                                     training_type: semi_supervised\n",
      "                                     transfer_learning_mode: False\n",
      "                                     use_early_stopping: False\n",
      "                                     use_fp16: False\n",
      "                                     use_projector: False\n",
      "                                     use_projector_out: False\n",
      "                                     warmup_epochs: 10\n",
      "                                     wd: 1e-06\n",
      "                                     workers: 0\n",
      "                                     world_size: -1\n",
      "INFO - 10/15/24 10:44:56 - 0:00:00 - The experiment will be stored in /home/icb/fatemehs.hashemig/models//hlca/swav-only_iloss0_closs0.0_num-prot-300_latent8-semi_aug-knn7_ep0.02_model-v1_dimensionality_reduction-pca_k_neighbors-7\n",
      "                                     \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dictionary:\n",
      " \tNum conditions: [9]\n",
      " \tEmbedding dim: [10]\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 2000 45 10\n",
      "\tMean/Var Layer in/out: 45 8\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  8 45 10\n",
      "\tOutput Layer in/out:  45 2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10/15/24 10:44:57 - 0:00:01 - Building data done with 493678 images loaded.\n",
      "INFO - 10/15/24 10:44:57 - 0:00:02 - SwavBase(\n",
      "                                       (scpoli_model): scpoli(\n",
      "                                         (embeddings): ModuleList(\n",
      "                                           (0): Embedding(9, 10, max_norm=1.0)\n",
      "                                         )\n",
      "                                         (encoder): Encoder(\n",
      "                                           (FC): Sequential(\n",
      "                                             (L0): CondLayers(\n",
      "                                               (expr_L): Linear(in_features=2000, out_features=45, bias=True)\n",
      "                                               (cond_L): Linear(in_features=10, out_features=45, bias=False)\n",
      "                                             )\n",
      "                                             (N0): LayerNorm((45,), eps=1e-05, elementwise_affine=False)\n",
      "                                             (A0): ReLU()\n",
      "                                             (D0): Dropout(p=0.05, inplace=False)\n",
      "                                           )\n",
      "                                           (mean_encoder): Linear(in_features=45, out_features=8, bias=True)\n",
      "                                           (log_var_encoder): Linear(in_features=45, out_features=8, bias=True)\n",
      "                                         )\n",
      "                                         (decoder): Decoder(\n",
      "                                           (FirstL): Sequential(\n",
      "                                             (L0): CondLayers(\n",
      "                                               (expr_L): Linear(in_features=8, out_features=45, bias=False)\n",
      "                                               (cond_L): Linear(in_features=10, out_features=45, bias=False)\n",
      "                                             )\n",
      "                                             (N0): LayerNorm((45,), eps=1e-05, elementwise_affine=False)\n",
      "                                             (A0): ReLU()\n",
      "                                             (D0): Dropout(p=0.05, inplace=False)\n",
      "                                           )\n",
      "                                           (HiddenL): Sequential()\n",
      "                                           (mean_decoder): Sequential(\n",
      "                                             (0): Linear(in_features=45, out_features=2000, bias=True)\n",
      "                                             (1): Softmax(dim=-1)\n",
      "                                           )\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (prototypes): Linear(in_features=8, out_features=300, bias=False)\n",
      "                                     )\n",
      "INFO - 10/15/24 10:44:57 - 0:00:02 - Building model done.\n",
      "INFO - 10/15/24 10:44:57 - 0:00:02 - Building optimizer done.\n",
      "INFO - 10/15/24 10:44:57 - 0:00:02 - no mixed precision\n"
     ]
    }
   ],
   "source": [
    "t.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a37c1b00-20d3-4249-b066-b4f91f1b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = t.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87704b3-61cb-4877-a815-53c7ce73dcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10/15/24 10:44:57 - 0:00:02 - loading the graph\n",
      "INFO - 10/15/24 10:44:57 - 0:00:02 - done, loaded graph with 548532 nodes\n",
      "INFO - 10/15/24 10:44:58 - 0:00:03 - setting graph number: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  ..., 0.000, 0.000,\n",
       "          0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "         [0.870, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  ..., 0.000, 0.000,\n",
       "          0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "         [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  ..., 0.000, 0.000,\n",
       "          0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "         [0.000, 0.672, 0.000, 0.000, 0.000, 0.000, 0.000,  ..., 0.000, 0.000,\n",
       "          0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "         [0.876, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  ..., 0.000, 0.000,\n",
       "          0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "         [0.000, 0.566, 0.000, 0.000, 0.000, 0.000, 0.000,  ..., 0.000, 0.000,\n",
       "          0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "         [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  ..., 0.000, 0.000,\n",
       "          0.000, 0.000, 0.000, 0.000, 0.000]]),\n",
       " 'labeled': tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=torch.float64),\n",
       " 'sizefactor': tensor([223.968, 261.112, 222.601, 196.732, 267.687, 211.573, 222.601]),\n",
       " 'batch': tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]),\n",
       " 'combined_batch': tensor([0, 0, 0, 0, 0, 0, 0]),\n",
       " 'celltypes': tensor([[ 0],\n",
       "         [32],\n",
       "         [ 0],\n",
       "         [ 0],\n",
       "         [32],\n",
       "         [ 0],\n",
       "         [ 0]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2915a928-bc2d-48d9-bb1c-b761703fe558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493678"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.knn_graph[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0702752-d61c-4d08-b3c8-53a2a38d27db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.graph_handler.default_knn_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fa39f52-1976-44db-bebd-f270b4f3aa93",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'scPoli' object has no attribute 'cell_type_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scpoli\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell_type_keys\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'scPoli' object has no attribute 'cell_type_keys'"
     ]
    }
   ],
   "source": [
    "self.get_scpoli().cell_type_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00e236f9-c37a-4325-be27-694002f988cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model = self.get_scpoli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffa6bed5-af01-4b39-9f25-6252ef4095ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "attr_dict = deepcopy(ref_model._get_public_attributes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7df21d4f-c2b8-4809-888a-e99559501472",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = scPoli\n",
    "init_params = cls._get_init_params_from_dict(attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e63fdea1-39b3-4c25-8fa3-7777e2c9f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_keys = init_params[\"cell_type_keys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ed3cc32-d3a3-4fde-8e6c-8ae384671202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cell_type']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c59eb2cd-6edb-45f8-963b-931cc6a852df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_key = cell_type_keys[0]\n",
    "adata = self.ref.adata\n",
    "labeled_indices = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c306f472-5c53-4ac2-aaf6-1e59fda32d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/apex-env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: None",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m uniq_cts \u001b[38;5;241m=\u001b[39m \u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcell_type_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabeled_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/apex-env/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/envs/apex-env/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/apex-env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "uniq_cts = adata.obs[cell_type_key][labeled_indices].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f53fcc1-8dee-434d-9435-721541a5005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dictionary:\n",
      " \tNum conditions: [3]\n",
      " \tEmbedding dim: [10]\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 64 10\n",
      "\tMean/Var Layer in/out: 64 8\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  8 64 10\n",
      "\tOutput Layer in/out:  64 4000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scpoli_query = scPoli.load_query_data(\n",
    "            adata=self.ref.adata,\n",
    "            reference_model=self.get_scpoli(),\n",
    "            labeled_indices=[],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85824215-0261-48b3-9374-bf8da9d8e8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 24837, 24837, 10820, 14507, 18344, 10163, 18344]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "199fc240-5fac-4bf9-b5f2-74b599aefbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, get_worker_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d682aa1-32a4-4cc1-9fb7-815a62a4dc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.utils.data._utils.worker.get_worker_info() -> Optional[torch.utils.data._utils.worker.WorkerInfo]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_worker_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7da1eea-18cf-49d8-a047-ce3e6a3687a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'worker_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[43mworker_info\u001b[49m\u001b[38;5;241m.\u001b[39mid\n",
      "\u001b[0;31mNameError\u001b[0m: name 'worker_info' is not defined"
     ]
    }
   ],
   "source": [
    "worker_id = worker_info.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc5bfe-ae23-44c2-9768-357aaf6ba019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
